2020年5月22日 09:36:36

### 目录

1. 运输层概述
2. UDP协议
3. TCP协议
4. TCP原理
5. TCP可靠性实现
6. TCP流量控制
7. TCP拥塞控制
8. TCP连接管理

### 1. 运输层概述

#### 1.1 进程间通信

从通信和信息处理的角度看，运输层向它上面的应用层提供通信服务，它属于面向通信部分的最高层，同时也是用户功能中的最低层。

两个主机进行通信实际上就是两个主机中的应用进程互相通信。 应用进程之间的通信又称为端到端的通信。

运输层提供应用进程间的逻辑通信。

运输层的一个很重要的功能就是复用和分用。应用层不同进程的报文通过不同的端口向下交到运输层，再往下就共用网络层提供的服务。

#### 1.2 与网络层区别

真正通信的实体是进程，网络层只是把数据送到主机，这无法完成通信，所以设计运输层完成进程最后一公里通信。

运输层为应用进程之间提供端到端的逻辑通信（但网络层是为主机之间提供逻辑通信）。

运输层还要对收到的报文进行差错检测。（网络层只检测帧头部CRC，对数据体不检测）

运输层需要有两种不同的运输协议，即面向连接的 TCP 和无连接的 UDP。  

#### 1.3 两种协议

传输控制协议 TCP  (Transmission Control Protocol)：当运输层采用面向连接的 TCP 协议时，尽管下面的网络是不可靠的（只提供尽最大努力服务），但这种逻辑通信信道就相当于一条全双工的可靠信道。

用户数据报协议 UDP  (User Datagram Protocol)：当运输层采用无连接的 UDP 协议时，这种逻辑通信信道是一条不可靠信道。 

两个对等运输实体在通信时传送的数据单位叫作运输协议数据单元 TPDU (Transport Protocol Data Unit)。

TCP 传送的数据单位协议是 TCP 报文段(segment)

UDP 传送的数据单位协议是 UDP 报文或用户数据报。 

UDP 在传送数据之前不需要先建立连接。对方的运输层在收到 UDP 报文后，不需要给出任何确认。虽然 UDP 不提供可靠交付，但在某些情况下 UDP 是一种最有效的工作方式。

TCP 则提供面向连接的服务。TCP 不提供广播或多播服务。由于 TCP 要提供可靠的、面向连接的运输服务，因此不可避免地增加了许多的开销。这不仅使协议数据单元的首部增大很多，还要占用许多的处理机资源。 

运输层的 UDP 用户数据报与网际层的IP数据报有很大区别。IP 数据报要经过互连网中许多路由器的存储转发，但 UDP 用户数据报是在运输层的端到端抽象的逻辑信道中传送的。

TCP 报文段是在运输层抽象的端到端逻辑信道中传送，这种信道是可靠的全双工信道。但这样的信道却不知道究竟经过了哪些路由器，而这些路由器也根本不知道上面的运输层是否建立了 TCP 连接。

#### 1.4 端口

运输层既然是进程间的通信，就需要像IP一样对进程进行标记，那就是端口。端口用一个 16 位端口号进行标志。

虽然通信的终点是应用进程，但我们可以把端口想象是通信的终点，因为我们只要把要传送的报文交到目的主机的某一个合适的目的端口，剩下的工作（即最后交付目的进程）就由 TCP 来完成。

### 2. UDP协议

#### 2.1 概述

UDP 只在 IP 的数据报服务之上增加了很少一点的功能，即端口的功能和差错检测的功能。

虽然 UDP 用户数据报只能提供不可靠的交付，但 UDP 在某些方面有其特殊的优点。

- UDP 是无连接的，即发送数据之前不需要建立连接。

- UDP 使用尽最大努力交付，即不保证可靠交付，同时也不使用拥塞控制。

- UDP 是面向报文的。UDP 没有拥塞控制，很适合多媒体通信的要求。

- UDP 支持一对一、一对多、多对一和多对多的交互通信。

- UDP 的首部开销小，只有 8 个字节。

UDP 因为没有拥塞控制，所以不会因网络拥塞而降低发送速率，会以一定的速率不停地发送数据，这样实时直播就得到了保证。不然播放会卡顿。

### 3. TCP协议

#### 3.1 概述

TCP 是面向连接的运输层协议。每一条 TCP 连接只能有两个端点(endpoint)，每一条 TCP 连接只能是点对点的（一对一）。 TCP 提供可靠交付的服务。TCP 提供全双工通信。面向字节流。 

- TCP 连接是一条虚连接而不是一条真正的物理连接。

- TCP 对应用进程一次把多长的报文发送到TCP 的缓存中是不关心的。
- TCP 根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP 发送的报文长度是应用进程给出的）。
- TCP 可把太长的数据块划分短一些再传送。TCP 也可等待积累有足够多的字节后再构成报文段发送出去。

#### 3.2 套接字

TCP 连接的端点不是主机，不是主机的IP 地址，不是应用进程，也不是运输层的协议端口。TCP 连接的端点叫做套接字(socket)或插口。

端口号拼接到(contatenated with) IP 地址即构成了套接字。这里socket与通信中socket和应用层的socket不同。

### 4. TCP原理

#### 4.1 停止等待协议

包括出差错的超时重传，所以必须要保存分组的副本，还要进行编号，设计超时RTT。

还有确认丢失和确认迟到。

使用上述的确认和重传机制，我们就可以在不可靠的传输网络上实现可靠的通信。

这种可靠传输协议常称为自动重传请求ARQ (Automatic Repeat reQuest)。

ARQ 表明重传的请求是自动进行的。接收方不需要请求发送方重传某个出错的分组 。

但停止等待协议的优点是简单，但缺点是信道利用率太低。 

#### 4.2 连续 ARQ 协议

这里是对ARQ的改进，传统ARQ是收到一个字节确认一下，这里是使用滑动窗口，只要确认最后一个字节，默认前面的字节都收到了。

接收方一般采用累积确认的方式。即不必对收到的分组逐个发送确认，而是对按序到达的最后一个分组发送确认，这样就表示：到这个分组为止的所有分组都已正确收到了。

累积确认有的优点是：容易实现，即使确认丢失也不必重传。缺点是：不能向发送方反映出接收方已经正确收到的所有分组的信息。

#### 4.3 可靠实现

- TCP 连接的每一端都必须设有两个窗口——一个发送窗口和一个接收窗口。

- TCP 的可靠传输机制用字节的序号进行控制。TCP 所有的确认都是基于序号而不是基于报文段。

- TCP 两端的四个窗口经常处于动态变化之中。
- TCP连接的往返时间 RTT 也不是固定不变的。需要使用特定的算法估算较为合理的重传时间。 

![image-20200522100602949](C:\code\github\java-interview\img\internet-24.png)

### 5. TCP可靠性实现

#### 5.1 以字节为单位的滑动窗口

![image-20200522100756152](C:\code\github\java-interview\img\internet-25.png)

发送缓存用来暂时存放：发送应用程序传送给发送方 TCP 准备发送的数据；TCP 已发送出但尚未收到确认的数据。

接收缓存用来暂时存放：按序到达的、但尚未被接收应用程序读取的数据；不按序到达的数据。

#### 5.2 超时重传时间的选择

重传机制是 TCP 中最重要和最复杂的问题之一。

TCP 每发送一个报文段，就对这个报文段设置一次计时器。只要计时器设置的重传时间到但还没有收到确认，就要重传这一报文段。

超时重传时间 RTO 的计算。

修正的 Karn 算法： 报文段每重传一次，就把 RTO 增大一些，当不再发生报文段的重传时，才根据报文段的往返时延更新平均往返时延 RTT 和超时重传时间 RTO 的数值。

#### 5.3 选择确认 SACK

接收方收到了和前面的字节流不连续的两个字节块。

如果这些字节的序号都在接收窗口之内，那么接收方就先收下这些数据，但要把这些信息准确地告诉发送方，使发送方不要再重复发送这些已收到的数据。

### 6. TCP流量控制

#### 6.1 利用滑动窗口实现流量控制

流量控制(flow control)就是让发送方的发送速率不要太快，既要让接收方来得及接收，也不要使网络发生拥塞。

利用滑动窗口机制可以很方便地在 TCP 连接上实现流量控制。

#### 6.2 持续计时器

TCP 为每一个连接设有一个持续计时器。

只要 TCP 连接的一方收到对方的零窗口通知，就启动持续计时器。

若持续计时器设置的时间到期，就发送一个零窗口探测报文段（仅携带 1 字节的数据），而对方就在确认这个探测报文段时给出了现在的窗口值。

若窗口仍然是零，则收到这个报文段的一方就重新设置持续计时器。若窗口不是零，则死锁的僵局就可以打破了。 

### 7. TCP拥塞控制

#### 7.1 比较

n拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。

n拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。

n流量控制往往指在给定的发送端和接收端之间的点对点通信量的控制。 

n流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。

![image-20200522101513755](C:\code\github\java-interview\img\internet-26.png)

#### 7.2 设计

开环控制方法就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。

闭环控制是基于反馈环路的概念。属于闭环控制的有以下几种措施： 

监测网络系统以便检测到拥塞在何时、何处发生。将拥塞发生的信息传送到可采取行动的地方。

调整网络系统的运行以解决出现的问题。

#### 7.3 慢开始和拥塞避免

发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。如再考虑到接收方的接收能力，则发送窗口还可能小于拥塞窗口。

发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。

##### 7.3.1 慢开始算法的原理

n在主机刚刚开始发送报文段时可先设置拥塞窗口 cwnd = 1，即设置为一个最大报文段 MSS 的数值。

n在每收到一个对新的报文段的确认后，将拥塞窗口加 1，即增加一个 MSS 的数值。

n用这样的方法逐步增大发送端的拥塞窗口 cwnd，可以使分组注入到网络的速率更加合理。 

##### 7.3.2 传输轮次

n使用慢开始算法后，每经过一个传输轮次，拥塞窗口 cwnd 就加倍。

n一个传输轮次所经历的时间其实就是往返时间 RTT。

n“传输轮次”更加强调：把拥塞窗口 cwnd 所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。

n例如，拥塞窗口 cwnd = 4，这时的往返时间 RTT 就是发送方连续发送 4 个报文段，并收到这 4 个报文段的确认，总共经历的时间。

##### 7.3.3 设置慢开始门限状态变量ssthresh

n慢开始门限 ssthresh 的用法如下：

n当 cwnd < ssthresh 时，使用慢开始算法。

n当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。

n当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞避免算法。

n拥塞避免算法的思路是让拥塞窗口 cwnd 缓慢地增大，即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1，而不是加倍，使拥塞窗口 cwnd 按线性规律缓慢增长。

##### 7.3.4 当网络出现拥塞时

n无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认），就要把慢开始门限 ssthresh 设置为出现拥塞时的发送方窗口值的一半（但不能小于2）。

n然后把拥塞窗口 cwnd 重新设置为 1，执行慢开始算法。

n这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。

![image-20200522101807308](C:\code\github\java-interview\img\internet-27.png)

当拥塞窗口 cwnd 增长到慢开始门限值 ssthresh 时（即当 cwnd = 16 时），就改为执行拥塞避免算法，拥塞窗口按线性规律增长。假定拥塞窗口的数值增长到 24 时，网络出现超时，表明网络拥塞了。更新后的 ssthresh 值变为 12（即发送窗口数值 24 的一半），拥塞窗口再重新设置为 1，并执行慢开始算法。当 cwnd = 12 时改为执行拥塞避免算法，拥塞窗口按按线性规律增长，每经过一个往返时延就增加一个 MSS 的大小。

##### 7.3.5 乘法减小

n“乘法减小“是指不论在慢开始阶段还是拥塞避免阶段，只要出现一次超时（即出现一次网络拥塞），就把慢开始门限值 ssthresh 设置为当前的拥塞窗口值乘以 0.5。

n当网络频繁出现拥塞时，ssthresh 值就下降得很快，以大大减少注入到网络中的分组数。

##### 7.3.6 加法增大

n“加法增大”是指执行拥塞避免算法后，在收到对所有报文段的确认后（即经过一个往返时间），就把拥塞窗口 cwnd增加一个 MSS 大小，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。

#### 7.4 快重传和快恢复

##### 7.4.1 快重传

快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认。这样做可以让发送方及早知道有报文段没有到达接收方。

发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段。

不难看出，快重传并非取消重传计时器，而是在某些情况下可更早地重传丢失的报文段。

##### 7.4.2 快恢复算法

当发送端收到连续三个重复的确认时，就执行“乘法减小”算法，把慢开始门限 ssthresh 减半。但接下去不执行慢开始算法。

(2)由于发送方现在认为网络很可能没有发生拥塞，因此现在不执行慢开始算法，即拥塞窗口 cwnd 现在不设置为 1，而是设置为慢开始门限 ssthresh 减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。

![image-20200522102109567](C:\code\github\java-interview\img\internet-28.png)

发送方的发送窗口的上限值应当取为接收方窗口 rwnd 和拥塞窗口 cwnd 这两个变量中较小的一个，即应按以下公式确定：

发送窗口的上限值 = Min [rwnd, cwnd]         (5-8)

当 rwnd < cwnd 时，是接收方的接收能力限制发送窗口的最大值。

当 cwnd < rwnd 时，则是网络的拥塞限制发送窗口的最大值。

### 8. TCP连接管理

#### 8.1 运输连接的三个阶段

n运输连接就有三个阶段，即：连接建立、数据传送和连接释放。运输连接的管理就是使运输连接的建立和释放都能正常地进行。

n连接建立过程中要解决以下三个问题：

n要使每一方能够确知对方的存在。

n要允许双方协商一些参数（如最大报文段长度，最大窗口大小，服务质量等）。

n能够对运输实体资源（如缓存大小，连接表中的项目等）进行分配。 

#### 8.2 三报文握手

![image-20200522102232154](C:\code\github\java-interview\img\internet-29.png)

A 的 TCP 向 B 发出连接请求报文段，其首部中的同步位 SYN = 1，并选择序号 seq = x，表明传送数据时的第一个数据字节的序号是 x。

B 的 TCP 收到连接请求报文段后，如同意，则发回确认。B 在确认报文段中应使 SYN = 1，使 ACK = 1，其确认号ack = x + 1，自己选择的序号 seq = y。

A 收到此报文段后向 B 给出确认，其 ACK = 1， 确认号 ack = y + 1。A 的 TCP 通知上层应用进程，连接已经建立。B 的 TCP 收到主机 A 的确认后，也通知其上层应用进程：TCP 连接已经建立。

>注意：这里SYN表示同步请求，是请求发送专用的，ACK表示应答回应，是回应回复专用的，所以只要是发送请求都是SYN=1关键字，回应都是ACK=1关键字。又因为SYN和ACK在报文中只有1位长度，需要带额外信息才能确认。SYN带seq，ACK带ack。每次回应的时候都是ack=seq+1。而请求新的seq=ack，表示对ack这条回应的再回应，不然不知道哪个消息。 

#### 8.3 连接释放

![image-20200522102830636](C:\code\github\java-interview\img\internet-30.png)

A 把连接释放报文段首部的 FIN = 1，其序号seq = u，等待 B 的确认。

B 发出确认，确认号 ack = u + 1，而这个报文段自己的序号 seq = v。TCP 服务器进程通知高层应用进程。 从 A 到 B 这个方向的连接就释放了，TCP 连接处于半关闭状态。B 若发送数据，A 仍要接收。

若 B 已经没有要向 A 发送的数据，其应用进程就通知 TCP 释放连接。 

A 收到连接释放报文段后，必须发出确认。 在确认报文段中 ACK=1，确认号 ack=w+1，自己的序号 seq=u+1。 

![image-20200522103032492](C:\code\github\java-interview\img\internet-31.png)

